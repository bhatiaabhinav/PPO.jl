using Statistics
using Flux
using Flux: unsqueeze

function tof32(ğ±::AbstractArray{<:Real, N})::AbstractArray{Float32, N} where N
    convert(AbstractArray{Float32, N}, ğ±)
end


const SQRT_2PI = Float32(sqrt(2Ï€))
const LOG_SQRT_2PI = Float32(log(SQRT_2PI))
const LOG_2PI = Float32(log(2Ï€))

@inline function log_nomal_prob(x::T, Î¼::T, Ïƒ::T)::T where {T<:Real}
    return -0.5 * ((x - Î¼) / Ïƒ)^2 - log(SQRT_2PI * Ïƒ)
end

@inline function log_nomal_prob(x::T, Î¼::T, Ïƒ::T, logÏƒ::T)::T where {T<:Real}
    return -0.5 * ((x - Î¼) / Ïƒ)^2 - LOG_SQRT_2PI - logÏƒ
end


batch(x) = reshape(x, size(x)..., 1)
batch(x::Real) = [x]
unbatch(x) = selectdim(x, ndims(x), 1)
unbatch(x::AbstractVector) = x[1]
unbatch_last(x) = selectdim(x, ndims(x), size(x, ndims(x)))
unbatch_last(x::AbstractVector) = x[end]


using Flux


"""
    clip gradients by global norm. Norm is calulated by concatenating all gradients into a single vector and then calculating the norm of that vector.

# Arguments
    gs: gradients dict. Access gradiens of parameter `p` by `gs[p]`
    ps: parameters list
    maxnorm: maximum norm allowed. If norm is greater than this, then all gradients are scaled down by the same factor so that the norm becomes equal to this value.
"""
function clip_global_norm!(gs, ps, maxnorm)
    norm = 0
    for p in ps
        !haskey(gs, p) && continue
        isnothing(gs[p]) && continue
        norm += sum(abs2, gs[p])
    end
    norm = sqrt(norm)
    if norm > maxnorm
        scale = maxnorm / norm
        for p in ps
            !haskey(gs, p) && continue
            isnothing(gs[p]) && continue
            gs[p] *= scale
        end
    end
    nothing
end


function make_adam_optim(lr, betas, epsilon, weight_decay)
    optim_chain = []
    if weight_decay > 0
        push!(optim_chain, WeightDecay(weight_decay))
    end
    push!(optim_chain, Adam(lr, betas, epsilon))
    return Flux.Optimiser(optim_chain...)
end


function cartesian_product(X::AbstractArray{Int}, Y::AbstractArray{Int})
    return [CartesianIndex(x, y) for x in X, y in Y]
end

function cartesian_product(Xdims::Int, Ydims::Int)
    return cartesian_product(1:Xdims, 1:Ydims)
end



function rollouts_parallel(envs, nsteps, actor, device, rng, progressmeter=false; reset_all=true)

    reset!(envs, reset_all; rng=rng)

    state_dim = size(state_space(envs), 1)
    isdiscrete = action_space(envs) isa IntegerSpace
    if isdiscrete
        nactions = length(action_space(envs))
    else
        action_dim = size(action_space(envs), 1)
    end
    M, N = nsteps, length(envs)

    if state_dim > 50
        ğ¬ = zeros(Float32, state_dim, M, N) |> device
    else
        ğ¬ = zeros(Float32, state_dim, M, N)
    end
    if isdiscrete
        ğš = zeros(Int, 1, M, N)
    else
        ğš = zeros(Float32, action_dim, M, N)
    end
    ğ« = zeros(Float32, 1, M, N)
    ğ­ = zeros(Float32, 1, M, N)
    ğ = zeros(Float32, 1, M, N)

    progress = Progress(M; color=:white, desc="Collecting trajectories", enabled=progressmeter)

    Flux.reset!(actor)
    for t in 1:M
        reset!(envs, false; rng=rng)
        ğ¬â‚œ = state(envs) |> tof32
        if state_dim > 50
            ğ¬[:, t, :] .= device(ğ¬â‚œ)
        else
            ğ¬[:, t, :] .= ğ¬â‚œ
        end
        if isdiscrete
            @assert actor isa PPOActorDiscrete
            if actor.recurtype âˆˆ (MARKOV, RECURRENT)
                ğ›‘â‚œ, logğ›‘â‚œ = get_probs_logprobs(actor, device(ğ¬â‚œ)) |> cpu
            elseif actor.recurtype == TRANSFORMER
                s_t = ğ¬[:, 1:t, :]
                if state_dim > 50
                    s_gpu = s_t
                else
                    s_gpu = s_t |> device
                end
                ğ›‘â‚œ, logğ›‘â‚œ = get_probs_logprobs(actor, s_gpu) |> cpu
                ğ›‘â‚œ, logğ›‘â‚œ = ğ›‘â‚œ[:, t, :], logğ›‘â‚œ[:, t, :]
                s_gpu = nothing
                s_t = nothing
            end
            ğšâ‚œ = reshape([sample(rng, 1:nactions, ProbabilityWeights(ğ›‘â‚œ[:, i])) for i in 1:N], 1, N)
            ğš[:, t, :] = ğšâ‚œ
        else
            @assert actor isa PPOActorContinuous
            if actor.recurtype âˆˆ (MARKOV, RECURRENT)
                ğšâ‚œ, logğ›‘â‚œ, logğ›”â‚œ = sample_action_logprobs(actor, rng, device(ğ¬â‚œ); return_logstd=true) |> cpu
            else
                ğšâ‚œ, logğ›‘â‚œ, logğ›”â‚œ = sample_action_logprobs(actor, rng, device(ğ¬[:, 1:t, :]); return_logstd=true) |> cpu
                ğšâ‚œ, logğ›‘â‚œ = ğšâ‚œ[:, end, :], logğ›‘â‚œ[:, end, :]
            end
            ğš[:, t, :] = ğšâ‚œ
        end

        if isdiscrete
            _ğšâ‚œ = ğšâ‚œ[1, :]
        else
            Tâ‚ = envs |> action_space |> eltype |> eltype
            _ğšâ‚œ = convert(Matrix{Tâ‚}, ğšâ‚œ) |> eachcol .|> copy    # eachcol makes it a vector of vectors
            _ğšâ‚œ = convert(Matrix{Tâ‚}, ğšâ‚œ)
        end
        step!(envs, _ğšâ‚œ; rng=rng)
        ğ«â‚œ = reward(envs)' |> tof32
        ğ«[:, t, :] = ğ«â‚œ
        ğ­â‚œ = in_absorbing_state(envs)' |> tof32
        ğ­[:, t, :] = ğ­â‚œ
        ğâ‚œ = (in_absorbing_state(envs) .|| truncated(envs))' |> tof32
        ğ[:, t, :] = ğâ‚œ
        next!(progress)
    end
    finish!(progress)
    return ğ¬, ğš, ğ«, ğ­, ğ
end